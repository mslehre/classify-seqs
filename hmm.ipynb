{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather HMM example\n",
    "Das Wetter bei deinem Übersee-Chatfreund lässt sich durch eine Markowkette $X_1,X_2,\\ldots$ mit\n",
    "Zustandsraum $Q=\\{\\texttt{sun},\\texttt{rain},\\texttt{storm}\\}$ und Übergangsmatrix\n",
    "$$A=(A[r,s])_{\\scriptsize r,s \\in Q} = \\begin{pmatrix}\n",
    "0.7 & 0.2 & 0.1\\\\\n",
    "0.3 & 0.5 & 0.2\\\\\n",
    "0.2 & 0.6 & 0.2\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "beschreiben (Reihen und Spalten in der Reihenfolge `sun`, `rain`, `storm`).\n",
    "\n",
    "Dabei sei $X_i$ das Wetter am $i$-ten Tag und $X_1=\\texttt{sun}$. Dein Freund verfolgt vom Wetter abhängig Aktivitäten entweder drinnen \n",
    "(`in`) oder draußen (`out`). Sei $\\Sigma:=\\{\\texttt{in},\\texttt{out}\\}$. Folgende Matrix\n",
    "beschreibe die vom Wetter abhängenden Wahrscheinlichkeiten (Wkeiten) der Aktivitäten\n",
    "$$B=\\big(B[q,s]\\big)_{\\scriptsize\\begin{array}{l}q\\in Q\\\\s\\in \\Sigma\\end{array}} = \\begin{pmatrix}\n",
    "0.4 & 0.6 \\\\\n",
    "0.8 & 0.2 \\\\\n",
    "0.9 & 0.1 \\\\\n",
    "\\end{pmatrix}\n",
    ".$$ \n",
    "Ablesebeispiel: Dein Freund bleibt mit Wkeit 0.9 drinnen, wenn es an dem Tag stürmt (Spalten in der Reihenfolge `in`, `out`).\n",
    "Beantworte folgende Fragen für das durch $Q,\\Sigma,A,B$ und $X_1$ gegebene Hidden-Markow-Modell.\n",
    "Was ist die Wkeit \n",
    "$$P(Y_1=Y_2=Y_3=\\texttt{in}),$$\n",
    "\n",
    "dass dein Freund am allen drei Tagen drinnen bleibt?\n",
    "\n",
    "![forward DP table](forwardManually.png)\n",
    "\n",
    "**Solution: P(Y=y) = 0.1308**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # number of states\n",
    "s = 2 # emission alphabet size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_init = np.array([[7, 2, 1], [3, 5, 2], [2, 6, 2]]) / 10.0\n",
    "B_init = np.array([[4, 6], [8, 2], [9, 1]]) / 10.0\n",
    "X1_dist = np.array([1., 0., 0.]) # starts with sun\n",
    "n, s = B_init.shape # number of states, emission alphabet size\n",
    "y = np.array([0, 0, 0]) # in, in, in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transitions:\n",
      " [[0.7 0.2 0.1]\n",
      " [0.3 0.5 0.2]\n",
      " [0.2 0.6 0.2]] \n",
      "emissions:\n",
      " [[0.4 0.6]\n",
      " [0.8 0.2]\n",
      " [0.9 0.1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"transitions:\\n\", A_init, \"\\nemissions:\\n\", B_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward recursion\n",
    "$$\\alpha[i,q] = B[q, y[i]] \\sum_{q'} \\alpha[i-1, q'] \\cdot A[q',q] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf variants of the transition and emission matrix\n",
    "A = tf.Variable(A_init, trainable = True)\n",
    "B = tf.Variable(B_init, trainable = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Variables and Algorithm\n",
    "$$ \\alpha(q,i) = \\sum_{x_1,\\ldots, x_{i-1}\\in Q} P(x_1,\\ldots, x_{i-1}, X_i=q, y_1,\\ldots, y_i)$$\n",
    "Initialization: \n",
    "$$ \\alpha(q, 1) = \\sum_{q\\in Q} P(X_1 = q)\\cdot B[q,y[0]]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(y # observation sequence\n",
    "           ):\n",
    "    \"\"\" Forward Algorithm for Computing Sequence Likelihood \"\"\"\n",
    "    ell = y.shape[0]\n",
    "    α = tf.Variable(np.zeros([ell, n]), trainable = False)\n",
    "    \n",
    "    # initialization\n",
    "    α[0].assign(tf.multiply(B[:, y[0]], X1_dist))\n",
    "    \n",
    "    # forward algorithm\n",
    "    for i in range(1, ell):\n",
    "        # compute i-th row of DP table\n",
    "        R = tf.linalg.matvec(A, α[i-1], transpose_a = True)\n",
    "        α[i].assign(tf.multiply(B[:, y[i]], R))\n",
    "    return α\n",
    "\n",
    "def emiProb(α):\n",
    "    return np.sum(α[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4    , 0.     , 0.     ],\n",
       "       [0.112  , 0.064  , 0.036  ],\n",
       "       [0.04192, 0.0608 , 0.02808]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "α = forward(y)\n",
    "α.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1308"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py = emiProb(α)\n",
    "Py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A HMM as a Special Case of a Recurrent Neural Network\n",
    "We use the notation of RNNs similar to that in [Dive into Deep Learning](https://d2l.ai/chapter_recurrent-neural-networks/bptt.html). $h_t$ is a size $n$ vector of RNN-\"hidden states\" (these are real numbers, not to be confused with the hidden states of HMMs, which are from $Q$).  \n",
    "$$ h_t = f(x_t, h_{t-1}; A, B)$$\n",
    "We chose the outputs\n",
    "$$ o_t = \\text{sum}(h_t) = h_t[0] + \\cdots + h_t[n-1] \\in [0,1]$$\n",
    "so that the final output $o_T$ is just the likelihood of the sequence $P(Y)$.\n",
    "This RNN does not need to produce intermediate outputs $o_t$ for $t<T$ as they are not used yet. However, they could be used in conjunction with a backwards pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMMCell\n",
    "As a template we use the code for [tf.keras.layers.SimpleRNNCell](https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/layers/recurrent.py#L1222-L1420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HMMCell import HMMCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the HMM cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=3, s=2\n",
      "output:\n",
      " [[<tf.Tensor: shape=(1,), dtype=int8, numpy=array([0], dtype=int8)>, <tf.Tensor: shape=(1, 1, 3), dtype=float32, numpy=array([[[0.5283019 , 0.3018868 , 0.16981131]]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-1.551169]], dtype=float32)>]] \n",
      "\n",
      "transition matrix A:\n",
      " [[[0.7 0.2 0.1]\n",
      "  [0.3 0.5 0.2]\n",
      "  [0.2 0.6 0.2]]]\n",
      "emission matrix B:\n",
      " [[[0.4 0.6]\n",
      "  [0.8 0.2]\n",
      "  [0.9 0.1]]]\n",
      "initial distribution I:\n",
      " [[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print (f\"n={n}, s={s}\")\n",
    "\n",
    "A_init = np.array([[[7, 2, 1], [3, 5, 2], [2, 6, 2]]]) / 10.0\n",
    "B_init = np.array([[[4, 6], [8, 2], [9, 1]]]) / 10.0\n",
    "I_init = np.array([[1, 1e-10, 1e-10]]) # start with X1=sun (very likely)\n",
    "\n",
    "# take ln to cancel out the softmax that is applied to obtain a stochastic matrix \n",
    "A_init = np.log(A_init)\n",
    "B_init = np.log(B_init)\n",
    "I_init = np.log(I_init)\n",
    "\n",
    "A_initializer = tf.keras.initializers.Constant(A_init)\n",
    "B_initializer = tf.keras.initializers.Constant(B_init)\n",
    "I_initializer = tf.keras.initializers.Constant(I_init)\n",
    "\n",
    "yi = np.array([[1., 0]]).astype(np.float32) # np.random.random([batch_size, s]).astype(np.float32)\n",
    "states = np.array([[[.4, 0, 0]]]).astype(np.float32) # np.random.random([batch_size, n]).astype(np.float32)\n",
    "hmmC = HMMCell(1, n,\n",
    "               transition_initializer=A_initializer,\n",
    "               emission_initializer=B_initializer,\n",
    "               init_initializer=I_initializer\n",
    "              )\n",
    "\n",
    "output = hmmC(yi, [0, states, [0.]])\n",
    "print(\"output:\\n\", output[0], \"\\n\")\n",
    "\n",
    "A = hmmC.A\n",
    "B = hmmC.B\n",
    "I = hmmC.I\n",
    "\n",
    "with np.printoptions(precision=5, suppress=True):\n",
    "    print(\"transition matrix A:\\n\", A.numpy())\n",
    "    print(\"emission matrix B:\\n\", B.numpy())\n",
    "    print(\"initial distribution I:\\n\", I.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "α=\n",
      " [[[[1.      0.      0.     ]]\n",
      "\n",
      "  [[0.5283  0.30189 0.16981]]\n",
      "\n",
      "  [[0.32049 0.46483 0.21468]]]] \n",
      "last column of forward table: [[[0.32049 0.46483 0.21468]]] \n",
      "log-likelihood= [[-2.03409]]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([[[1, 0],[1, 0],[1, 0]]]).astype(np.float32)\n",
    "hmm = tf.keras.layers.RNN(hmmC, return_sequences = True, return_state = True)\n",
    "  \n",
    "alpha, _, lastcol, loglik = hmm(inputs)\n",
    "alpha = alpha[1]\n",
    "\n",
    "print()\n",
    "with np.printoptions(precision=5, suppress=True):\n",
    "    print (\"α=\\n\", alpha.numpy(),\n",
    "       \"\\nlast column of forward table:\", lastcol.numpy(),\n",
    "      \"\\nlog-likelihood=\", loglik.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 100, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dishonest_casino import get_casino_dataset\n",
    "batch_size = 32\n",
    "ds = get_casino_dataset().repeat().batch(batch_size)\n",
    "\n",
    "for inputs in ds.take(1):\n",
    "    pass\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "u=2\n",
    "dcc = HMMCell(u,n)\n",
    "Q = dcc(inputs[:,0,:], [tf.zeros(batch_size, dtype=tf.int8),\n",
    "                    tf.ones([batch_size, u, s], dtype=tf.float32), \n",
    "                    tf.zeros([batch_size, u], dtype=tf.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model\n",
    "F = tf.keras.layers.RNN(dcc, return_state = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pars(cell):\n",
    "    with np.printoptions(precision=5, suppress=True):\n",
    "        print(\"transition matrices A:\\n\", cell.A.numpy())\n",
    "        print(\"emission matrices B:\\n\", cell.B.numpy())\n",
    "        print(\"initial distributions I:\\n\", cell.I.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition matrices A:\n",
      " [[[0.47595 0.52405]\n",
      "  [0.50636 0.49364]]\n",
      "\n",
      " [[0.50539 0.49461]\n",
      "  [0.51257 0.48743]]]\n",
      "emission matrices B:\n",
      " [[[0.17278 0.16369 0.16078 0.16603 0.16941 0.16732]\n",
      "  [0.16977 0.17147 0.15949 0.16716 0.16677 0.16534]]\n",
      "\n",
      " [[0.15911 0.17146 0.17244 0.16072 0.16531 0.17096]\n",
      "  [0.16709 0.16701 0.16473 0.17497 0.159   0.16719]]]\n",
      "initial distributions I:\n",
      " [[0.49281 0.50719]\n",
      " [0.48817 0.51183]]\n"
     ]
    }
   ],
   "source": [
    "print_pars(dcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss test: 179.12921142578125\n"
     ]
    }
   ],
   "source": [
    "def loss(model, y):\n",
    "  alpha, _, lastcol, loglik = model(y)\n",
    "  L = -tf.reduce_mean(loglik)\n",
    "  return L\n",
    "\n",
    "L = loss(F, inputs)\n",
    "#print(f\"likelihoods = {lik}\\nloss (avg neg log lik)= {loss}\")\n",
    "print(\"Loss test: {}\".format(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Initial Loss: 179.12921142578125\n"
     ]
    }
   ],
   "source": [
    "model = F\n",
    "loss_value, grads = grad(model, inputs)\n",
    "\n",
    "print(\"Step: {}, Initial Loss: {}\".format(opt.iterations.numpy(),\n",
    "                                          loss_value.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 178.150\n",
      "transition matrices A:\n",
      " [[[0.56331 0.43669]\n",
      "  [0.59109 0.40891]]\n",
      "\n",
      " [[0.5839  0.4161 ]\n",
      "  [0.58814 0.41186]]]\n",
      "emission matrices B:\n",
      " [[[0.15836 0.15185 0.15454 0.15488 0.15917 0.22122]\n",
      "  [0.15617 0.15932 0.15366 0.15663 0.15701 0.21721]]\n",
      "\n",
      " [[0.15054 0.15757 0.15922 0.14934 0.1588  0.22454]\n",
      "  [0.15878 0.15385 0.15264 0.16323 0.15306 0.21844]]]\n",
      "initial distributions I:\n",
      " [[0.46905 0.53095]\n",
      " [0.46379 0.53621]]\n",
      "Epoch 002: Loss: 177.186\n",
      "Epoch 004: Loss: 177.240\n",
      "Epoch 006: Loss: 177.115\n",
      "Epoch 008: Loss: 177.221\n",
      "Epoch 010: Loss: 177.295\n",
      "transition matrices A:\n",
      " [[[0.67023 0.32977]\n",
      "  [0.51555 0.48445]]\n",
      "\n",
      " [[0.65858 0.34142]\n",
      "  [0.53839 0.46161]]]\n",
      "emission matrices B:\n",
      " [[[0.14986 0.14704 0.14789 0.15096 0.15049 0.25376]\n",
      "  [0.15246 0.16035 0.15651 0.15136 0.15427 0.22505]]\n",
      "\n",
      " [[0.14681 0.15078 0.15062 0.14705 0.15165 0.25309]\n",
      "  [0.15752 0.1542  0.15177 0.15757 0.1526  0.22633]]]\n",
      "initial distributions I:\n",
      " [[0.07118 0.92882]\n",
      " [0.16596 0.83404]]\n",
      "Epoch 012: Loss: 177.271\n",
      "Epoch 014: Loss: 177.260\n",
      "Epoch 016: Loss: 176.887\n",
      "Epoch 018: Loss: 176.505\n",
      "Epoch 020: Loss: 176.210\n",
      "transition matrices A:\n",
      " [[[0.87639 0.12361]\n",
      "  [0.07496 0.92504]]\n",
      "\n",
      " [[0.88348 0.11652]\n",
      "  [0.07641 0.92359]]]\n",
      "emission matrices B:\n",
      " [[[0.1156  0.11253 0.11063 0.11524 0.11482 0.43118]\n",
      "  [0.17197 0.16849 0.1695  0.16709 0.17311 0.14983]]\n",
      "\n",
      " [[0.11739 0.11478 0.11268 0.11746 0.11682 0.42087]\n",
      "  [0.17269 0.16888 0.17028 0.16727 0.17365 0.14723]]]\n",
      "initial distributions I:\n",
      " [[0.06631 0.93369]\n",
      " [0.09104 0.90896]]\n",
      "Epoch 022: Loss: 176.357\n",
      "Epoch 024: Loss: 176.520\n",
      "Epoch 026: Loss: 176.355\n",
      "Epoch 028: Loss: 176.271\n",
      "Epoch 030: Loss: 176.330\n",
      "transition matrices A:\n",
      " [[[0.85765 0.14235]\n",
      "  [0.05444 0.94556]]\n",
      "\n",
      " [[0.85858 0.14142]\n",
      "  [0.05511 0.94489]]]\n",
      "emission matrices B:\n",
      " [[[0.10339 0.10303 0.10226 0.10601 0.10169 0.48362]\n",
      "  [0.16364 0.17037 0.17316 0.16822 0.16582 0.15879]]\n",
      "\n",
      " [[0.10388 0.1036  0.10281 0.10647 0.10211 0.48113]\n",
      "  [0.16377 0.17049 0.17331 0.16836 0.16595 0.15813]]]\n",
      "initial distributions I:\n",
      " [[0.02311 0.97689]\n",
      " [0.02747 0.97253]]\n",
      "Epoch 032: Loss: 176.447\n",
      "Epoch 034: Loss: 176.286\n",
      "Epoch 036: Loss: 176.364\n",
      "Epoch 038: Loss: 176.387\n",
      "Epoch 040: Loss: 176.498\n",
      "transition matrices A:\n",
      " [[[0.85372 0.14628]\n",
      "  [0.0515  0.9485 ]]\n",
      "\n",
      " [[0.85404 0.14596]\n",
      "  [0.05171 0.94829]]]\n",
      "emission matrices B:\n",
      " [[[0.10319 0.10222 0.10135 0.10158 0.0977  0.49396]\n",
      "  [0.16924 0.16836 0.16475 0.16831 0.16561 0.16374]]\n",
      "\n",
      " [[0.1033  0.10236 0.10146 0.10168 0.09782 0.49337]\n",
      "  [0.16921 0.16845 0.1648  0.16837 0.16557 0.16359]]]\n",
      "initial distributions I:\n",
      " [[0.01055 0.98945]\n",
      " [0.01244 0.98756]]\n",
      "Epoch 042: Loss: 176.317\n",
      "Epoch 044: Loss: 176.201\n",
      "Epoch 046: Loss: 176.495\n",
      "Epoch 048: Loss: 176.488\n",
      "Epoch 050: Loss: 176.170\n",
      "transition matrices A:\n",
      " [[[0.85467 0.14533]\n",
      "  [0.05003 0.94997]]\n",
      "\n",
      " [[0.85475 0.14525]\n",
      "  [0.05007 0.94993]]]\n",
      "emission matrices B:\n",
      " [[[0.1009  0.10024 0.10161 0.09938 0.09922 0.49865]\n",
      "  [0.172   0.15808 0.16573 0.16604 0.16501 0.17314]]\n",
      "\n",
      " [[0.10097 0.10033 0.10158 0.09944 0.09929 0.49839]\n",
      "  [0.17207 0.15801 0.16574 0.16604 0.16505 0.1731 ]]]\n",
      "initial distributions I:\n",
      " [[0.01072 0.98928]\n",
      " [0.0123  0.9877 ]]\n"
     ]
    }
   ],
   "source": [
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "\n",
    "num_epochs = 51\n",
    "m = 20 # training batches\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "  # Training loop - using batches\n",
    "  for y in ds.take(m):\n",
    "    # Optimize the model\n",
    "    loss_value, grads = grad(model, y)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # Track progress\n",
    "    epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "\n",
    "    # End epoch\n",
    "  train_loss_results.append(epoch_loss_avg.result())\n",
    "\n",
    "  if epoch % 2 == 0:\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}\".format(epoch, epoch_loss_avg.result()))\n",
    "  if epoch % 10 == 0:\n",
    "    print_pars(dcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition matrices A:\n",
      " [[[0.85467 0.14533]\n",
      "  [0.05003 0.94997]]\n",
      "\n",
      " [[0.85475 0.14525]\n",
      "  [0.05007 0.94993]]]\n",
      "emission matrices B:\n",
      " [[[0.1009  0.10024 0.10161 0.09938 0.09922 0.49865]\n",
      "  [0.172   0.15808 0.16573 0.16604 0.16501 0.17314]]\n",
      "\n",
      " [[0.10097 0.10033 0.10158 0.09944 0.09929 0.49839]\n",
      "  [0.17207 0.15801 0.16574 0.16604 0.16505 0.1731 ]]]\n",
      "initial distributions I:\n",
      " [[0.01072 0.98928]\n",
      " [0.0123  0.9877 ]]\n"
     ]
    }
   ],
   "source": [
    "print_pars(dcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
