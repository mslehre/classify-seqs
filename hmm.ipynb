{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather HMM example\n",
    "Das Wetter bei deinem Übersee-Chatfreund lässt sich durch eine Markowkette $X_1,X_2,\\ldots$ mit\n",
    "Zustandsraum $Q=\\{\\texttt{sun},\\texttt{rain},\\texttt{storm}\\}$ und Übergangsmatrix\n",
    "$$A=(A[r,s])_{\\scriptsize r,s \\in Q} = \\begin{pmatrix}\n",
    "0.7 & 0.2 & 0.1\\\\\n",
    "0.3 & 0.5 & 0.2\\\\\n",
    "0.2 & 0.6 & 0.2\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "beschreiben (Reihen und Spalten in der Reihenfolge `sun`, `rain`, `storm`).\n",
    "\n",
    "Dabei sei $X_i$ das Wetter am $i$-ten Tag und $X_1=\\texttt{sun}$. Dein Freund verfolgt vom Wetter abhängig Aktivitäten entweder drinnen \n",
    "(`in`) oder draußen (`out`). Sei $\\Sigma:=\\{\\texttt{in},\\texttt{out}\\}$. Folgende Matrix\n",
    "beschreibe die vom Wetter abhängenden Wahrscheinlichkeiten (Wkeiten) der Aktivitäten\n",
    "$$B=\\big(B[q,s]\\big)_{\\scriptsize\\begin{array}{l}q\\in Q\\\\s\\in \\Sigma\\end{array}} = \\begin{pmatrix}\n",
    "0.4 & 0.6 \\\\\n",
    "0.8 & 0.2 \\\\\n",
    "0.9 & 0.1 \\\\\n",
    "\\end{pmatrix}\n",
    ".$$ \n",
    "Ablesebeispiel: Dein Freund bleibt mit Wkeit 0.9 drinnen, wenn es an dem Tag stürmt (Spalten in der Reihenfolge `in`, `out`).\n",
    "Beantworte folgende Fragen für das durch $Q,\\Sigma,A,B$ und $X_1$ gegebene Hidden-Markow-Modell.\n",
    "Was ist die Wkeit \n",
    "$$P(Y_1=Y_2=Y_3=\\texttt{in}),$$\n",
    "\n",
    "dass dein Freund am allen drei Tagen drinnen bleibt?\n",
    "\n",
    "![forward DP table](forwardManually.png)\n",
    "\n",
    "**Solution: P(Y=y) = 0.1308**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # number of states\n",
    "s = 2 # emission alphabet size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_init = np.array([[7, 2, 1], [3, 5, 2], [2, 6, 2]]) / 10.0\n",
    "B_init = np.array([[4, 6], [8, 2], [9, 1]]) / 10.0\n",
    "X1_dist = np.array([1., 0., 0.]) # starts with sun\n",
    "n, s = B_init.shape # number of states, emission alphabet size\n",
    "y = np.array([0, 0, 0]) # in, in, in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transitions:\n",
      " [[0.7 0.2 0.1]\n",
      " [0.3 0.5 0.2]\n",
      " [0.2 0.6 0.2]] \n",
      "emissions:\n",
      " [[0.4 0.6]\n",
      " [0.8 0.2]\n",
      " [0.9 0.1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"transitions:\\n\", A_init, \"\\nemissions:\\n\", B_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward recursion\n",
    "$$\\alpha[i,q] = B[q, y[i]] \\sum_{q'} \\alpha[i-1, q'] \\cdot A[q',q] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf variants of the transition and emission matrix\n",
    "A = tf.Variable(A_init, trainable = True)\n",
    "B = tf.Variable(B_init, trainable = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Variables and Algorithm\n",
    "$$ \\alpha(q,i) = \\sum_{x_1,\\ldots, x_{i-1}\\in Q} P(x_1,\\ldots, x_{i-1}, X_i=q, y_1,\\ldots, y_i)$$\n",
    "Initialization: \n",
    "$$ \\alpha(q, 1) = \\sum_{q\\in Q} P(X_1 = q)\\cdot B[q,y[0]]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(y # observation sequence\n",
    "           ):\n",
    "    \"\"\" Forward Algorithm for Computing Sequence Likelihood \"\"\"\n",
    "    ell = y.shape[0]\n",
    "    α = tf.Variable(np.zeros([ell, n]), trainable = False)\n",
    "    \n",
    "    # initialization\n",
    "    α[0].assign(tf.multiply(B[:, y[0]], X1_dist))\n",
    "    \n",
    "    # forward algorithm\n",
    "    for i in range(1, ell):\n",
    "        # compute i-th row of DP table\n",
    "        R = tf.linalg.matvec(A, α[i-1], transpose_a = True)\n",
    "        α[i].assign(tf.multiply(B[:, y[i]], R))\n",
    "    return α\n",
    "\n",
    "def emiProb(α):\n",
    "    return np.sum(α[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4    , 0.     , 0.     ],\n",
       "       [0.112  , 0.064  , 0.036  ],\n",
       "       [0.04192, 0.0608 , 0.02808]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "α = forward(y)\n",
    "α.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1308"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py = emiProb(α)\n",
    "Py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A HMM as a Special Case of a Recurrent Neural Network\n",
    "We use the notation of RNNs similar to that in [Dive into Deep Learning](https://d2l.ai/chapter_recurrent-neural-networks/bptt.html). $h_t$ is a size $n$ vector of RNN-\"hidden states\" (these are real numbers, not to be confused with the hidden states of HMMs, which are from $Q$).  \n",
    "$$ h_t = f(x_t, h_{t-1}; A, B)$$\n",
    "We chose the outputs\n",
    "$$ o_t = \\text{sum}(h_t) = h_t[0] + \\cdots + h_t[n-1] \\in [0,1]$$\n",
    "so that the final output $o_T$ is just the likelihood of the sequence $P(Y)$.\n",
    "This RNN does not need to produce intermediate outputs $o_t$ for $t<T$ as they are not used yet. However, they could be used in conjunction with a backwards pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMMCell\n",
    "As a template we use the code for [tf.keras.layers.SimpleRNNCell](https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/layers/recurrent.py#L1222-L1420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HMMCell import HMMCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the HMM cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=3, s=2\n",
      "output:\n",
      " [[<tf.Tensor: shape=(1,), dtype=int8, numpy=array([0], dtype=int8)>, <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.112, 0.064, 0.036]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.212], dtype=float32)>]] \n",
      "\n",
      "transition matrix A:\n",
      " [[0.7 0.2 0.1]\n",
      " [0.3 0.5 0.2]\n",
      " [0.2 0.6 0.2]]\n",
      "emission matrix B:\n",
      " [[0.4 0.6]\n",
      " [0.8 0.2]\n",
      " [0.9 0.1]]\n",
      "initial distribution I:\n",
      " [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print (f\"n={n}, s={s}\")\n",
    "\n",
    "A_init = np.array([[7, 2, 1], [3, 5, 2], [2, 6, 2]]) / 10.0\n",
    "B_init = np.array([[4, 6], [8, 2], [9, 1]]) / 10.0\n",
    "I_init = np.array([1, 1e-10, 1e-10]) # start with X1=sun (very likely)\n",
    "\n",
    "# take ln to cancel out the softmax that is applied to obtain a stochastic matrix \n",
    "A_init = np.log(A_init)\n",
    "B_init = np.log(B_init)\n",
    "I_init = np.log(I_init)\n",
    "\n",
    "A_initializer = tf.keras.initializers.Constant(A_init)\n",
    "B_initializer = tf.keras.initializers.Constant(B_init)\n",
    "I_initializer = tf.keras.initializers.Constant(I_init)\n",
    "\n",
    "yi = np.array([[1., 0]]).astype(np.float32) # np.random.random([batch_size, s]).astype(np.float32)\n",
    "states = np.array([[.4, 0, 0]]).astype(np.float32) # np.random.random([batch_size, n]).astype(np.float32)\n",
    "hmmC = HMMCell(n,\n",
    "               transition_initializer=A_initializer,\n",
    "               emission_initializer=B_initializer,\n",
    "               init_initializer=I_initializer\n",
    "              )\n",
    "\n",
    "output = hmmC(yi, [0, states, 0.])\n",
    "print(\"output:\\n\", output[0], \"\\n\")\n",
    "\n",
    "A = hmmC.A\n",
    "B = hmmC.B\n",
    "I = hmmC.I\n",
    "\n",
    "with np.printoptions(precision=5, suppress=True):\n",
    "    print(\"transition matrix A:\\n\", A.numpy())\n",
    "    print(\"emission matrix B:\\n\", B.numpy())\n",
    "    print(\"initial distribution I:\\n\", I.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "α=\n",
      " [[[0.4     0.      0.     ]\n",
      "  [0.112   0.064   0.036  ]\n",
      "  [0.04192 0.0608  0.02808]]] \n",
      "last column of forward table: [[0.04192 0.0608  0.02808]] \n",
      "likelihood= [0.1308]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([[[1, 0],[1, 0],[1, 0]]]).astype(np.float32)\n",
    "hmm = tf.keras.layers.RNN(hmmC, return_sequences = True, return_state = True)\n",
    "  \n",
    "alpha, _, lastcol, loglik = hmm(inputs)\n",
    "alpha = alpha[1]\n",
    "\n",
    "print()\n",
    "with np.printoptions(precision=5, suppress=True):\n",
    "    print (\"α=\\n\", alpha.numpy(),\n",
    "       \"\\nlast column of forward table:\", lastcol.numpy(),\n",
    "      \"\\nlikelihood=\", loglik.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dishonest_casino import get_casino_dataset\n",
    "batch_size = 128\n",
    "ds = get_casino_dataset().repeat().batch(batch_size)\n",
    "\n",
    "for inputs in ds.take(1):\n",
    "    pass\n",
    "#inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "dcc = HMMCell(n)\n",
    "Q = dcc(inputs[:,0,:], [tf.zeros(batch_size, dtype=tf.int8),\n",
    "                    tf.zeros([batch_size, s], dtype=tf.float32), \n",
    "                    tf.zeros(n, dtype=tf.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model\n",
    "F = tf.keras.layers.RNN(dcc, return_state = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pars(cell):\n",
    "    with np.printoptions(precision=5, suppress=True):\n",
    "        print(\"transition matrix A:\\n\", cell.A.numpy())\n",
    "        print(\"emission matrix B:\\n\", cell.B.numpy())\n",
    "        print(\"initial distribution I:\\n\", cell.I.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition matrix A:\n",
      " [[0.49935 0.50065]\n",
      " [0.51548 0.48452]]\n",
      "emission matrix B:\n",
      " [[0.17617 0.16513 0.16303 0.16009 0.16353 0.17204]\n",
      " [0.17101 0.16197 0.17033 0.16747 0.16684 0.16237]]\n",
      "initial distribution I:\n",
      " [0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "print_pars(dcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss test: 21.50402069091797\n"
     ]
    }
   ],
   "source": [
    "def loss(model, y):\n",
    "  alpha, _, lastcol, lik = model(y)\n",
    "  L = -tf.reduce_mean(tf.math.log(lik))\n",
    "  return L\n",
    "\n",
    "L = loss(F, inputs)\n",
    "#print(f\"likelihoods = {lik}\\nloss (avg neg log lik)= {loss}\")\n",
    "print(\"Loss test: {}\".format(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Initial Loss: 21.50402069091797\n"
     ]
    }
   ],
   "source": [
    "model = F\n",
    "loss_value, grads = grad(model, inputs)\n",
    "\n",
    "print(\"Step: {}, Initial Loss: {}\".format(opt.iterations.numpy(),\n",
    "                                          loss_value.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 21.427\n",
      "transition matrix A:\n",
      " [[0.60341 0.39659]\n",
      " [0.60875 0.39125]]\n",
      "emission matrix B:\n",
      " [[0.15669 0.15583 0.15121 0.15254 0.15548 0.22825]\n",
      " [0.15481 0.1545  0.15858 0.16032 0.16056 0.21123]]\n",
      "initial distribution I:\n",
      " [0.3965 0.6035]\n",
      "Epoch 001: Loss: 21.395\n",
      "Epoch 002: Loss: 21.387\n",
      "Epoch 003: Loss: 21.389\n",
      "Epoch 004: Loss: 21.375\n",
      "Epoch 005: Loss: 21.364\n",
      "Epoch 006: Loss: 21.352\n",
      "Epoch 007: Loss: 21.327\n",
      "Epoch 008: Loss: 21.347\n",
      "Epoch 009: Loss: 21.352\n",
      "Epoch 010: Loss: 21.356\n",
      "transition matrix A:\n",
      " [[0.88031 0.11969]\n",
      " [0.09572 0.90428]]\n",
      "emission matrix B:\n",
      " [[0.12781 0.11884 0.12697 0.1186  0.12585 0.38192]\n",
      " [0.16649 0.17684 0.17013 0.17013 0.17805 0.13836]]\n",
      "initial distribution I:\n",
      " [0.10255 0.89745]\n",
      "Epoch 011: Loss: 21.352\n",
      "Epoch 012: Loss: 21.349\n",
      "Epoch 013: Loss: 21.358\n",
      "Epoch 014: Loss: 21.336\n",
      "Epoch 015: Loss: 21.333\n",
      "Epoch 016: Loss: 21.329\n",
      "Epoch 017: Loss: 21.337\n",
      "Epoch 018: Loss: 21.332\n",
      "Epoch 019: Loss: 21.332\n",
      "Epoch 020: Loss: 21.338\n",
      "transition matrix A:\n",
      " [[0.84935 0.15065]\n",
      " [0.07144 0.92856]]\n",
      "emission matrix B:\n",
      " [[0.109   0.11272 0.11056 0.10873 0.11207 0.44692]\n",
      " [0.16775 0.17251 0.16901 0.16832 0.16779 0.15462]]\n",
      "initial distribution I:\n",
      " [0.04434 0.95566]\n",
      "Epoch 021: Loss: 21.334\n",
      "Epoch 022: Loss: 21.339\n",
      "Epoch 023: Loss: 21.347\n",
      "Epoch 024: Loss: 21.348\n",
      "Epoch 025: Loss: 21.341\n",
      "Epoch 026: Loss: 21.332\n",
      "Epoch 027: Loss: 21.332\n",
      "Epoch 028: Loss: 21.345\n",
      "Epoch 029: Loss: 21.322\n",
      "Epoch 030: Loss: 21.353\n",
      "transition matrix A:\n",
      " [[0.86454 0.13546]\n",
      " [0.06102 0.93898]]\n",
      "emission matrix B:\n",
      " [[0.10389 0.10568 0.1091  0.10446 0.11337 0.4635 ]\n",
      " [0.16769 0.16454 0.16977 0.17118 0.16513 0.16168]]\n",
      "initial distribution I:\n",
      " [0.02249 0.97751]\n",
      "Epoch 031: Loss: 21.336\n",
      "Epoch 032: Loss: 21.341\n",
      "Epoch 033: Loss: 21.348\n",
      "Epoch 034: Loss: 21.315\n",
      "Epoch 035: Loss: 21.340\n",
      "Epoch 036: Loss: 21.325\n",
      "Epoch 037: Loss: 21.350\n",
      "Epoch 038: Loss: 21.339\n",
      "Epoch 039: Loss: 21.346\n",
      "Epoch 040: Loss: 21.334\n",
      "transition matrix A:\n",
      " [[0.85935 0.14065]\n",
      " [0.05291 0.94709]]\n",
      "emission matrix B:\n",
      " [[0.10446 0.10591 0.10176 0.10035 0.10902 0.47851]\n",
      " [0.16495 0.16572 0.16404 0.16638 0.16889 0.17001]]\n",
      "initial distribution I:\n",
      " [0.01538 0.98462]\n",
      "Epoch 041: Loss: 21.354\n",
      "Epoch 042: Loss: 21.334\n",
      "Epoch 043: Loss: 21.345\n",
      "Epoch 044: Loss: 21.318\n",
      "Epoch 045: Loss: 21.350\n",
      "Epoch 046: Loss: 21.335\n",
      "Epoch 047: Loss: 21.314\n",
      "Epoch 048: Loss: 21.352\n",
      "Epoch 049: Loss: 21.356\n",
      "Epoch 050: Loss: 21.321\n",
      "transition matrix A:\n",
      " [[0.87642 0.12358]\n",
      " [0.05053 0.94947]]\n",
      "emission matrix B:\n",
      " [[0.10697 0.10848 0.10511 0.0977  0.10046 0.48128]\n",
      " [0.16734 0.16655 0.16305 0.17443 0.16606 0.16257]]\n",
      "initial distribution I:\n",
      " [0.0113 0.9887]\n",
      "Epoch 051: Loss: 21.328\n",
      "Epoch 052: Loss: 21.333\n",
      "Epoch 053: Loss: 21.325\n",
      "Epoch 054: Loss: 21.334\n",
      "Epoch 055: Loss: 21.326\n",
      "Epoch 056: Loss: 21.345\n",
      "Epoch 057: Loss: 21.354\n",
      "Epoch 058: Loss: 21.328\n",
      "Epoch 059: Loss: 21.324\n",
      "Epoch 060: Loss: 21.333\n",
      "transition matrix A:\n",
      " [[0.86164 0.13836]\n",
      " [0.0507  0.9493 ]]\n",
      "emission matrix B:\n",
      " [[0.09728 0.10215 0.10192 0.10212 0.09863 0.4979 ]\n",
      " [0.16427 0.16812 0.16553 0.16469 0.16932 0.16807]]\n",
      "initial distribution I:\n",
      " [0.00933 0.99067]\n",
      "Epoch 061: Loss: 21.307\n",
      "Epoch 062: Loss: 21.339\n",
      "Epoch 063: Loss: 21.338\n",
      "Epoch 064: Loss: 21.327\n",
      "Epoch 065: Loss: 21.347\n",
      "Epoch 066: Loss: 21.349\n",
      "Epoch 067: Loss: 21.341\n",
      "Epoch 068: Loss: 21.352\n",
      "Epoch 069: Loss: 21.303\n",
      "Epoch 070: Loss: 21.342\n",
      "transition matrix A:\n",
      " [[0.8367  0.1633 ]\n",
      " [0.05239 0.94761]]\n",
      "emission matrix B:\n",
      " [[0.10302 0.10234 0.09986 0.10095 0.09769 0.49614]\n",
      " [0.16894 0.16779 0.16874 0.16734 0.16384 0.16334]]\n",
      "initial distribution I:\n",
      " [0.00651 0.99349]\n",
      "Epoch 071: Loss: 21.340\n",
      "Epoch 072: Loss: 21.338\n",
      "Epoch 073: Loss: 21.338\n",
      "Epoch 074: Loss: 21.362\n",
      "Epoch 075: Loss: 21.324\n",
      "Epoch 076: Loss: 21.346\n",
      "Epoch 077: Loss: 21.337\n",
      "Epoch 078: Loss: 21.336\n",
      "Epoch 079: Loss: 21.346\n",
      "Epoch 080: Loss: 21.337\n",
      "transition matrix A:\n",
      " [[0.85121 0.14879]\n",
      " [0.05012 0.94988]]\n",
      "emission matrix B:\n",
      " [[0.09787 0.10016 0.09865 0.1005  0.10434 0.49849]\n",
      " [0.16355 0.16476 0.16976 0.16542 0.16673 0.16978]]\n",
      "initial distribution I:\n",
      " [0.00595 0.99405]\n",
      "Epoch 081: Loss: 21.312\n",
      "Epoch 082: Loss: 21.335\n",
      "Epoch 083: Loss: 21.336\n",
      "Epoch 084: Loss: 21.319\n",
      "Epoch 085: Loss: 21.348\n",
      "Epoch 086: Loss: 21.344\n",
      "Epoch 087: Loss: 21.360\n",
      "Epoch 088: Loss: 21.320\n",
      "Epoch 089: Loss: 21.321\n",
      "Epoch 090: Loss: 21.345\n",
      "transition matrix A:\n",
      " [[0.8403  0.1597 ]\n",
      " [0.04953 0.95047]]\n",
      "emission matrix B:\n",
      " [[0.0995  0.105   0.10034 0.10239 0.09779 0.49498]\n",
      " [0.16736 0.16729 0.17141 0.16163 0.1663  0.16601]]\n",
      "initial distribution I:\n",
      " [0.00554 0.99446]\n",
      "Epoch 091: Loss: 21.348\n",
      "Epoch 092: Loss: 21.329\n",
      "Epoch 093: Loss: 21.325\n",
      "Epoch 094: Loss: 21.329\n",
      "Epoch 095: Loss: 21.341\n",
      "Epoch 096: Loss: 21.349\n",
      "Epoch 097: Loss: 21.345\n",
      "Epoch 098: Loss: 21.327\n",
      "Epoch 099: Loss: 21.329\n",
      "Epoch 100: Loss: 21.341\n",
      "transition matrix A:\n",
      " [[0.84571 0.15429]\n",
      " [0.05021 0.94979]]\n",
      "emission matrix B:\n",
      " [[0.09996 0.10442 0.10565 0.10045 0.09677 0.49275]\n",
      " [0.16447 0.16369 0.17307 0.16535 0.16909 0.16433]]\n",
      "initial distribution I:\n",
      " [0.00456 0.99544]\n",
      "Epoch 101: Loss: 21.319\n",
      "Epoch 102: Loss: 21.341\n",
      "Epoch 103: Loss: 21.340\n",
      "Epoch 104: Loss: 21.326\n",
      "Epoch 105: Loss: 21.341\n",
      "Epoch 106: Loss: 21.336\n",
      "Epoch 107: Loss: 21.324\n",
      "Epoch 108: Loss: 21.335\n",
      "Epoch 109: Loss: 21.334\n",
      "Epoch 110: Loss: 21.341\n",
      "transition matrix A:\n",
      " [[0.84348 0.15652]\n",
      " [0.05027 0.94973]]\n",
      "emission matrix B:\n",
      " [[0.09555 0.0999  0.09639 0.10562 0.0987  0.50384]\n",
      " [0.16431 0.1671  0.16984 0.16497 0.16613 0.16764]]\n",
      "initial distribution I:\n",
      " [0.00388 0.99612]\n",
      "Epoch 111: Loss: 21.337\n",
      "Epoch 112: Loss: 21.334\n",
      "Epoch 113: Loss: 21.341\n",
      "Epoch 114: Loss: 21.338\n",
      "Epoch 115: Loss: 21.343\n",
      "Epoch 116: Loss: 21.350\n",
      "Epoch 117: Loss: 21.364\n",
      "Epoch 118: Loss: 21.313\n",
      "Epoch 119: Loss: 21.333\n",
      "Epoch 120: Loss: 21.350\n",
      "transition matrix A:\n",
      " [[0.86023 0.13977]\n",
      " [0.05212 0.94788]]\n",
      "emission matrix B:\n",
      " [[0.10386 0.0998  0.09565 0.10232 0.10871 0.48965]\n",
      " [0.16639 0.16053 0.16168 0.17212 0.16839 0.17089]]\n",
      "initial distribution I:\n",
      " [0.0037 0.9963]\n",
      "Epoch 121: Loss: 21.343\n",
      "Epoch 122: Loss: 21.336\n",
      "Epoch 123: Loss: 21.337\n",
      "Epoch 124: Loss: 21.338\n",
      "Epoch 125: Loss: 21.343\n",
      "Epoch 126: Loss: 21.330\n",
      "Epoch 127: Loss: 21.317\n",
      "Epoch 128: Loss: 21.325\n",
      "Epoch 129: Loss: 21.343\n",
      "Epoch 130: Loss: 21.330\n",
      "transition matrix A:\n",
      " [[0.84638 0.15362]\n",
      " [0.05034 0.94966]]\n",
      "emission matrix B:\n",
      " [[0.10344 0.09788 0.10191 0.09552 0.10307 0.49818]\n",
      " [0.16948 0.16674 0.16933 0.1648  0.16294 0.1667 ]]\n",
      "initial distribution I:\n",
      " [0.00288 0.99712]\n",
      "Epoch 131: Loss: 21.298\n",
      "Epoch 132: Loss: 21.320\n",
      "Epoch 133: Loss: 21.304\n",
      "Epoch 134: Loss: 21.335\n",
      "Epoch 135: Loss: 21.353\n",
      "Epoch 136: Loss: 21.342\n",
      "Epoch 137: Loss: 21.336\n",
      "Epoch 138: Loss: 21.338\n",
      "Epoch 139: Loss: 21.315\n",
      "Epoch 140: Loss: 21.352\n",
      "transition matrix A:\n",
      " [[0.84431 0.15569]\n",
      " [0.04948 0.95052]]\n",
      "emission matrix B:\n",
      " [[0.10436 0.09665 0.09463 0.10327 0.10118 0.49991]\n",
      " [0.16643 0.16933 0.16524 0.16281 0.16931 0.16689]]\n",
      "initial distribution I:\n",
      " [0.00249 0.99751]\n",
      "Epoch 141: Loss: 21.321\n",
      "Epoch 142: Loss: 21.358\n",
      "Epoch 143: Loss: 21.339\n",
      "Epoch 144: Loss: 21.342\n",
      "Epoch 145: Loss: 21.368\n",
      "Epoch 146: Loss: 21.353\n",
      "Epoch 147: Loss: 21.355\n",
      "Epoch 148: Loss: 21.326\n",
      "Epoch 149: Loss: 21.352\n",
      "Epoch 150: Loss: 21.340\n",
      "transition matrix A:\n",
      " [[0.86263 0.13737]\n",
      " [0.05215 0.94785]]\n",
      "emission matrix B:\n",
      " [[0.1035  0.09959 0.09862 0.09897 0.09901 0.50031]\n",
      " [0.16507 0.17091 0.16725 0.16456 0.17034 0.16188]]\n",
      "initial distribution I:\n",
      " [0.00207 0.99793]\n",
      "Epoch 151: Loss: 21.350\n",
      "Epoch 152: Loss: 21.360\n",
      "Epoch 153: Loss: 21.350\n",
      "Epoch 154: Loss: 21.328\n",
      "Epoch 155: Loss: 21.333\n",
      "Epoch 156: Loss: 21.336\n",
      "Epoch 157: Loss: 21.336\n",
      "Epoch 158: Loss: 21.328\n",
      "Epoch 159: Loss: 21.329\n",
      "Epoch 160: Loss: 21.356\n",
      "transition matrix A:\n",
      " [[0.85402 0.14598]\n",
      " [0.05276 0.94724]]\n",
      "emission matrix B:\n",
      " [[0.10942 0.10446 0.09577 0.10361 0.09687 0.48987]\n",
      " [0.16477 0.16794 0.1636  0.17087 0.16737 0.16545]]\n",
      "initial distribution I:\n",
      " [0.00211 0.99789]\n",
      "Epoch 161: Loss: 21.351\n",
      "Epoch 162: Loss: 21.326\n",
      "Epoch 163: Loss: 21.362\n",
      "Epoch 164: Loss: 21.318\n",
      "Epoch 165: Loss: 21.361\n",
      "Epoch 166: Loss: 21.339\n",
      "Epoch 167: Loss: 21.340\n",
      "Epoch 168: Loss: 21.341\n",
      "Epoch 169: Loss: 21.358\n",
      "Epoch 170: Loss: 21.335\n",
      "transition matrix A:\n",
      " [[0.85286 0.14714]\n",
      " [0.05081 0.94919]]\n",
      "emission matrix B:\n",
      " [[0.09777 0.10122 0.10118 0.10005 0.10516 0.49462]\n",
      " [0.16424 0.16662 0.16496 0.16749 0.16705 0.16964]]\n",
      "initial distribution I:\n",
      " [0.00206 0.99794]\n",
      "Epoch 171: Loss: 21.316\n",
      "Epoch 172: Loss: 21.370\n",
      "Epoch 173: Loss: 21.323\n",
      "Epoch 174: Loss: 21.332\n",
      "Epoch 175: Loss: 21.318\n",
      "Epoch 176: Loss: 21.337\n",
      "Epoch 177: Loss: 21.330\n",
      "Epoch 178: Loss: 21.340\n",
      "Epoch 179: Loss: 21.336\n",
      "Epoch 180: Loss: 21.354\n",
      "transition matrix A:\n",
      " [[0.86104 0.13896]\n",
      " [0.04696 0.95304]]\n",
      "emission matrix B:\n",
      " [[0.09573 0.10027 0.11003 0.10062 0.09864 0.49471]\n",
      " [0.16679 0.16392 0.16795 0.16254 0.17201 0.16679]]\n",
      "initial distribution I:\n",
      " [0.00188 0.99812]\n",
      "Epoch 181: Loss: 21.327\n",
      "Epoch 182: Loss: 21.323\n",
      "Epoch 183: Loss: 21.346\n",
      "Epoch 184: Loss: 21.328\n",
      "Epoch 185: Loss: 21.349\n",
      "Epoch 186: Loss: 21.344\n",
      "Epoch 187: Loss: 21.339\n",
      "Epoch 188: Loss: 21.341\n",
      "Epoch 189: Loss: 21.350\n",
      "Epoch 190: Loss: 21.355\n",
      "transition matrix A:\n",
      " [[0.85164 0.14836]\n",
      " [0.0441  0.9559 ]]\n",
      "emission matrix B:\n",
      " [[0.10323 0.10487 0.09708 0.09862 0.09904 0.49716]\n",
      " [0.16609 0.16423 0.16276 0.16402 0.17831 0.16458]]\n",
      "initial distribution I:\n",
      " [0.00168 0.99832]\n",
      "Epoch 191: Loss: 21.343\n",
      "Epoch 192: Loss: 21.340\n",
      "Epoch 193: Loss: 21.352\n",
      "Epoch 194: Loss: 21.326\n",
      "Epoch 195: Loss: 21.339\n",
      "Epoch 196: Loss: 21.347\n",
      "Epoch 197: Loss: 21.337\n",
      "Epoch 198: Loss: 21.329\n",
      "Epoch 199: Loss: 21.342\n",
      "Epoch 200: Loss: 21.360\n",
      "transition matrix A:\n",
      " [[0.83965 0.16035]\n",
      " [0.04768 0.95232]]\n",
      "emission matrix B:\n",
      " [[0.10481 0.09599 0.09516 0.10379 0.09706 0.50318]\n",
      " [0.16546 0.16977 0.16908 0.16476 0.16592 0.16502]]\n",
      "initial distribution I:\n",
      " [0.00176 0.99824]\n"
     ]
    }
   ],
   "source": [
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "m = 32 # training batches\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "  # Training loop - using batches\n",
    "  for y in ds.take(m):\n",
    "    # Optimize the model\n",
    "    loss_value, grads = grad(model, y)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # Track progress\n",
    "    epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "\n",
    "    # End epoch\n",
    "  train_loss_results.append(epoch_loss_avg.result())\n",
    "\n",
    "  if epoch % 1 == 0:\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}\".format(epoch, epoch_loss_avg.result()))\n",
    "  if epoch % 10 == 0:\n",
    "    print_pars(dcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition matrix A:\n",
      " [[0.83965 0.16035]\n",
      " [0.04768 0.95232]]\n",
      "emission matrix B:\n",
      " [[0.10481 0.09599 0.09516 0.10379 0.09706 0.50318]\n",
      " [0.16546 0.16977 0.16908 0.16476 0.16592 0.16502]]\n",
      "initial distribution I:\n",
      " [0.00176 0.99824]\n"
     ]
    }
   ],
   "source": [
    "print_pars(dcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = loss(F, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=21.334452>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
